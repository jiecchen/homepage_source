<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Algorithm | Mind Recorder]]></title>
  <link href="http://xmerge.me/blog/categories/algorithm/atom.xml" rel="self"/>
  <link href="http://xmerge.me/"/>
  <updated>2015-11-03T15:17:15-05:00</updated>
  <id>http://xmerge.me/</id>
  <author>
    <name><![CDATA[xmerge]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Quantile Problem in Streaming Model]]></title>
    <link href="http://xmerge.me/blog/2014/08/13/quantile-sketch/"/>
    <updated>2014-08-13T20:55:04-04:00</updated>
    <id>http://xmerge.me/blog/2014/08/13/quantile-sketch</id>
    <content type="html"><![CDATA[<p>I will give a deterministic approximation algorithm that constructs a data structure through a single pass of the a data stream, uses only $O(\log n / \epsilon)$ words space. For all $k$, such data structure is able to give a $(1 + \epsilon)$-approximation to the $k$th smallest item.</p>

<p>Before starting to describe our algorithm, let’s first clarify the model we use, and I will also recap some basic terminologies for those who are not familiar with streaming algorithms.</p>

<h2 id="the-model">The Model</h2>
<p>To make life easier, we only consider the most basic data stream model <strong>vanilla model</strong>. In such model, there will be a sequence of $m$ items, each item is an element among one of $1, 2, \ldots, n$.</p>

<h2 id="some-terms">Some Terms</h2>
<p>We say $\hat{Q}$ is a $(1 + \epsilon)$-approximation to an positive real $Q$ if $|Q - \hat{Q}| &lt; \epsilon Q$.</p>

<h2 id="the-problem">The Problem</h2>
<p>We slightly modified the classical Quantile Problem. In our setting, we want to design an algorithm which produces a data structure $\sigma$ via processing a data stream for only one pass. After the processing step, $\sigma$ is able to give $(1 + \epsilon)$-approximation to the $k$th smallest item (items may repeat) in the data stream, of course, $k$ is an integer and can be arbitrarily chosen from $[1, m]$. Our goal is to minimize the space needed to produce this $\sigma$ and in the meantime, the processing time per item should be as small as possible.</p>

<h2 id="the-algorithm">The Algorithm</h2>
<p>The original idea is quite straightforward: we simply maintain a sequence of buckets. The $i$th bucket $B_i = ( ~(1 + \epsilon)^{(i-1)}, (1 + \epsilon)^i~]$, and we also associate a counter $C_i$ to each $B_i$. It is clear that we can use $C_i$ to record how many items are trapped by the bucket $B_i$, through only one pass of the stream. Hence the sequence of $B_i$ is exactly the data structure $\sigma$ we need.</p>

<p>Now let’s consider how we can answer a query $k$. Here is the way:</p>

<ul>
  <li>scan the counters $C_i$ with incremental index</li>
  <li>sum up all counters scanned until the total &gt;= $k$</li>
  <li>suppose we stop at the index $i$, return the average of the interval $B_i$</li>
</ul>

<p>One can easily see that the returned value is a $(1 + \epsilon)$-approximation to the $k$th smallest item.</p>

<h2 id="performance-analysis">Performance Analysis</h2>
<p>Now we give the space and time usage for above algorithm.</p>

<h3 id="space-usage">Space Usage</h3>
<p>First, what is the space usage of the above algorithm? It is clear that the dominant space cost is the number of the buckets. Suppose we need at least $w$ buckets (hence the space usage will be bounded by $O(w)$), we need the following condition to ensure that we have enough buckets to cover all the items:</p>

<blockquote>
  <p>$(1 + \epsilon)^w = \Theta(n)$</p>
</blockquote>

<p>It implies $w = \Theta(\frac{\log n}{\log (1 + \epsilon)}) \overset{\epsilon~\text{is small} }{=} \Theta(\frac{log n}{\epsilon})$ hence the space is bounded by $O(\log n / \epsilon)$.</p>

<h3 id="processing-time">Processing Time</h3>
<p>Now we analyze the processing time per item. When a new item comes, the only thing we need to do is to locate the bucket that traps it, so that we can increment the corresponding counter. Suppose the item is $h$, then the index $i(h)$ of the corresponding bucket can be calculated by the formula:</p>

<blockquote>
  <p>$i(h) = \lceil \log h / \log (1 + \epsilon) \rceil$</p>
</blockquote>

<p>Which shows the processing time per time is $O(1)$.</p>

<h3 id="query-time">Query Time</h3>
<p>We are also interested in the processing time per query. It is trivial to see that the time is bound by $O(\log n / \epsilon)$ since we can give the correct answer anyway by scan all the buckets/counters. However, if we are not working in dynamic data stream i.e. all queries are answered after we have completed the single pass over the data stream, we will have better solution. First we spend $O(log n / \epsilon)$ time to scan the buckets, and then it will cost only $O(\log \log n + \log \frac{1}{\epsilon})$ for each query. We leave the details to the reader.</p>

<h2 id="conclusion">Conclusion</h2>
<p>An python implementation of our algorithm can be found in <a href="https://github.com/jiecchen/StreamLib/blob/master/streamlib/sketch/quantile.py">github</a> where they consider the <strong><em>Restrict Turnsitle Model</em></strong> which is  more general than our setting here. If the reader has some knowledge on <em>Sketch</em>, he will soon realize that our algorithm actually produces a linear mergable sketch, which is extremely useful in distributed computing. One can check the given <code>github</code> link to figure out how can two sketches be merged to one.</p>

<p>This algorithm came to me when <a href="http://meng6.net">@meng6</a> asked the algorithm for Quantile Problem under streaming model, however, it is almost sure that such a straightforward algorithm should have been published in some paper long ago which I could not find.</p>

<p>Anyway, I think a deterministic algorithm using only $O(\log n / \epsilon)$ space and $O(1)$ processing time should be near-optimal for our problem.</p>

]]></content>
  </entry>
  
</feed>
